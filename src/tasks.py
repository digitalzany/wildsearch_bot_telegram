import logging
import tempfile

import boto3
import pandas as pd
from celery import Celery
from envparse import env
from seller_stats.category_stats import CategoryStats
from seller_stats.formatters import format_currency as fcur
from seller_stats.formatters import format_number as fnum
from seller_stats.formatters import format_quantity as fquan
from seller_stats.loaders import ScrapinghubLoader
from seller_stats.transformers import WildsearchCrawlerWildberriesTransformer as wb_transformer
from telegram import Bot

from .amplitude_helper import AmplitudeLogger
from .models import LogCommandItem, get_subscribed_to_wb_categories_updates, user_get_by
from .scrapinghub_helper import wb_category_export

env.read_envfile()

celery = Celery('tasks')
celery.conf.update(
    broker_url=env('REDIS_URL'),
    task_always_eager=env('CELERY_ALWAYS_EAGER', cast=bool, default=False),
    task_serializer='pickle',  # we transfer binary data like photos or voice messages,
    accept_content=['pickle'],
    redis_max_connections=env('CELERY_REDIS_MAX_CONNECTIONS', default=None),
)

# –≤–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏
logger = logging.getLogger(__name__)

# –≤–∫–ª—é—á–∞–µ–º Amplitude
if env('AMPLITUDE_API_KEY', default=None) is not None:
    amplitude = AmplitudeLogger(env('AMPLITUDE_API_KEY'))

bot = Bot(env('TELEGRAM_API_TOKEN'))
s3 = boto3.client('s3')


def get_cat_update_users():
    users = get_subscribed_to_wb_categories_updates()
    return list(map(lambda x: x.chat_id, users))


@celery.task()
def calculate_wb_category_stats(job_id, chat_id):
    data = ScrapinghubLoader(job_id=job_id, transformer=wb_transformer()).load()
    stats = CategoryStats(data=data)

    stats.calculate_monthly_stats()

    message = generate_category_stats_message(stats=stats)
    bot.send_message(chat_id=chat_id, text=message, parse_mode='Markdown', disable_web_page_preview=True)

    export_file = generate_category_stats_file(stats)
    bot.send_document(
        chat_id=chat_id,
        document=export_file,
        filename=f'{stats.category_name()} –Ω–∞ Wildberries.xlsx',
    )

    send_category_requests_count_message.delay(chat_id)
    track_amplitude.delay(chat_id=chat_id, event='Received WB category analyses')


@celery.task()
def schedule_wb_category_export(category_url: str, chat_id: int, log_id):
    log_item = LogCommandItem.objects(id=log_id).first()

    try:
        wb_category_export(category_url, chat_id)
        message = '‚è≥ –ú—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∞—à –∑–∞–ø—Ä–æ—Å. –ö–æ–≥–¥–∞ –≤—Å–µ –±—É–¥–µ—Ç –≥–æ—Ç–æ–≤–æ, –≤—ã –ø–æ–ª—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\n\n–ë–æ–ª—å—à–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (—Å–≤—ã—à–µ 1 —Ç—ã—Å. —Ç–æ–≤–∞—Ä–æ–≤) –º–æ–≥—É—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è –¥–æ –æ–¥–Ω–æ–≥–æ —á–∞—Å–∞.\n\n–ú–∞–ª–µ–Ω—å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤ —Ç–µ—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–∏–Ω—É—Ç.'
        check_requests_count_recovered.apply_async((), {'chat_id': chat_id}, countdown=24 * 60 * 60 + 60)
        log_item.set_status('success')
    except Exception as e:
        message = '–ò–∑–≤–∏–Ω–∏—Ç–µ, –º—ã —Å–µ–π—á–∞—Å –Ω–µ –º–æ–∂–µ–º –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∞—à –∑–∞–ø—Ä–æ—Å ‚Äì —É –Ω–∞—Å –æ–±—Ä–∞–∑–æ–≤–∞–ª–∞—Å—å —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∞—è –æ—á–µ—Ä–µ–¥—å –Ω–∞ –∞–Ω–∞–ª–∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–π. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–¥–æ–∂–¥–∏—Ç–µ –Ω–µ–º–Ω–æ–≥–æ –∏ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –∑–∞–ø—Ä–æ—Å —Å–Ω–æ–≤–∞.'
        track_amplitude.delay(chat_id=chat_id, event='Received "Too long queue" error')
        pass

    bot.send_message(chat_id=chat_id, text=message)


@celery.task()
def send_category_requests_count_message(chat_id: int):
    user = user_get_by(chat_id=chat_id)

    emojis_left = ''.join(map(lambda x: 'üåï', range(user.catalog_requests_left_count())))
    emojis_used = ''.join(map(lambda x: 'üåë', range(user.today_catalog_requests_count())))
    emojis = emojis_left + emojis_used

    message = f'–í–∞–º –¥–æ—Å—Ç—É–ø–Ω–æ {user.catalog_requests_left_count()} –∏–∑ {user.daily_catalog_requests_limit} –∑–∞–ø—Ä–æ—Å–æ–≤\n{emojis}\n\n–õ–∏–º–∏—Ç –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–∏—Ç—Å—è —á–µ—Ä–µ–∑ 24 —á–∞—Å–∞ —Å –º–æ–º–µ–Ω—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞.'

    bot.send_message(chat_id=chat_id, text=message)


@celery.task()
def check_requests_count_recovered(chat_id: int):
    user = user_get_by(chat_id=chat_id)

    if user.catalog_requests_left_count() == user.daily_catalog_requests_limit:
        # here we are limiting the maximum number of emojis to 10
        # emoji = ''.join(map(lambda x: 'üåï', range(min(user.daily_catalog_requests_limit, 10))))
        # message = f'ü§ò –†–æ–∫-–Ω-—Ä–æ–ª–ª! –í–∞–º –¥–æ—Å—Ç—É–ø–Ω–æ {user.daily_catalog_requests_limit} –Ω–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π Wildberries –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.\n{emoji}'
        # bot.send_message(chat_id=chat_id, text=message)

        logger.info('Placeholder for sending recovered requests messages called')


@celery.task()
def track_amplitude(chat_id: int, event: str, event_properties=None, timestamp=None):
    if amplitude:
        user = user_get_by(chat_id=chat_id)
        amplitude.log(
            user_id=chat_id,
            event=event,
            user_properties={
                'Telegram chat ID': user.chat_id,
                'Name': user.full_name,
                'Telegram user name': user.user_name,
                'Daily catalog request limit': user.daily_catalog_requests_limit,
                'Subscribed to WB categories updates': user.subscribe_to_wb_categories_updates,
            },
            event_properties=event_properties,
            timestamp=timestamp,
        )


def generate_category_stats_message(stats):
    df = stats.df

    return f"""
[{stats.category_name()}]({stats.category_url()})

–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤: `{fnum(df.sku.sum())}`

–°–∞–º—ã–π –¥–æ—Ä–æ–≥–æ–π: {fcur(df.price.max())}
–°–∞–º—ã–π –¥–µ—à–µ–≤—ã–π: {fcur(df.price.min())}
–°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞: {fcur(df.price.mean())}

–ü—Ä–æ–¥–∞–∂ –≤—Å–µ–≥–æ: {fquan(df.purchases.sum())} (–Ω–∞ {fcur(df.turnover.sum())})
–í —Å—Ä–µ–¥–Ω–µ–º –ø—Ä–æ–¥–∞—é—Ç—Å—è –ø–æ: {fquan(df.purchases.mean())} (–Ω–∞ {fcur(df.turnover.mean())})
–ú–µ–¥–∏–∞–Ω–∞ –ø—Ä–æ–¥–∞–∂: {fquan(df.purchases.median())} (–Ω–∞ {fcur(df.turnover.median())})
"""


def generate_category_stats_file(stats):
    temp_file = tempfile.NamedTemporaryFile(suffix='.xlsx', prefix='wb_category_', mode='r+b', delete=True)

    writer = pd.ExcelWriter(temp_file.name)
    stats.df.to_excel(writer, sheet_name='–¢–æ–≤–∞—Ä—ã', index=None, header=True)
    stats.price_distribution().to_excel(writer, sheet_name='–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂', index=None, header=True)
    writer.save()

    return temp_file
